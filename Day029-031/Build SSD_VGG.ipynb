{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssd import build_ssd\n",
    "from layers.box_utils import *\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torchvision\n",
    "import pickle\n",
    "from layers import box_utils\n",
    "from layers import Detect\n",
    "from layers import functions\n",
    "from layers import modules\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt as sqrt\n",
    "from itertools import product as product\n",
    "\n",
    "from torch.autograd import Function\n",
    "from layers.box_utils import decode, nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 詳細模型結構在 ssd.py\n",
    "ssd_net = build_ssd(\"train\", size=300, num_classes=21)\n",
    "ssd_net.load_weights(\"./demo/ssd300_mAP_77.43_v2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'num_classes': 21,\n",
    "    'lr_steps': (80000, 100000, 120000),\n",
    "    'max_iter': 120000,\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],\n",
    "    'min_dim': 300,\n",
    "    'steps': [8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "    'variance': [0.1, 0.2],\n",
    "    'clip': True,\n",
    "    'name': 'VOC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratios：使用 6 張 Feature Map，每一張上方有預設的 anchor boxes，而 Boxes aspect ratio 可以自己設定\n",
    "\n",
    "feature_maps：使用 feature map 大小為 [38x38, 19x19, 10x10, 5x5, 3x3, 1x1]\n",
    "\n",
    "min_sizes 和 max_sizes 可藉由下面的算式算出，由作者自行設計\n",
    "\n",
    "steps：Feature map 回放回原本 300*300 的比例，如 38 要回放為 300 大概就是 8 倍\n",
    "\n",
    "variance：Training 的一個 trick，加速收斂，詳見：https://github.com/rykov8/ssd_keras/issues/53"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sizes 和 max_sizes 的計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "min_sizes:  [30.0, 60.0, 111.0, 162.0, 213.0, 264.0]\nmax_sizes:  [60.0, 111.0, 162.0, 213.0, 264.0, 315.0]\n"
    }
   ],
   "source": [
    "# source: https://blog.csdn.net/gbyy42299/article/details/81235891\n",
    "import math\n",
    "\n",
    "min_dim = 300\n",
    "\n",
    "# 產生 Default Box 的 layer，可以更改。許多改進都是基於此處\n",
    "# conv4_3 => 38 x 38\n",
    "# fc7 => 19 x 19\n",
    "# conv6_2 => 10 x 10\n",
    "# conv7_2 => 5 x 5\n",
    "# conv8_2 => 3 x 3\n",
    "# conv9_2 => 1 x 1\n",
    "mbox_source_layers = ['conv4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'conv9_2']\n",
    "\n",
    "# 長寬比\n",
    "# 這裡即是論文中所說的 Smin = 0.2 和 Smax = 0.9 的初始值，經過下面的運算即可得到 min_sizes 和 max_sizes\n",
    "min_ratio = 20\n",
    "max_ratio = 90\n",
    "\n",
    "# 取長寬的間距步長（這裡等於 17），可以用一個具體的數值代替\n",
    "step = int(math.floor((max_ratio - min_ratio) / (len(mbox_source_layers) - 2)))\n",
    "\n",
    "min_sizes = []\n",
    "max_sizes = []\n",
    "for ratio in range(min_ratio, max_ratio + 1, step):\n",
    "    # 從 min_ratio 至 max_ratio，每隔 17 就取一個值賦值給 ratio\n",
    "    min_sizes.append(min_dim * ratio / 100.)\n",
    "    max_sizes.append(min_dim * (ratio + step) / 100.)\n",
    "\n",
    "min_sizes = [min_dim * 10 / 100.] + min_sizes\n",
    "max_sizes = [min_dim * 20 / 100.] + max_sizes\n",
    "\n",
    "# steps 需要仔細理解，即計算卷積層產生的 Default Box 距離原圖的步長，先驗框中心點的坐標會乘以 step\n",
    "# 相當於從特徵映射位置映射回原圖位置，比如 conv4_3 輸出特徵圖大小為 38 * 38，而輸入的圖片為 300 * 300\n",
    "# 所以 38 * 8 約等於 300，所以映射步長為 8\n",
    "steps = [8, 16, 32, 64, 100, 300]\n",
    "aspect_ratios = [\n",
    "    [2],\n",
    "    [2, 3],\n",
    "    [2, 3],\n",
    "    [2, 3],\n",
    "    [2],\n",
    "    [2]\n",
    "]\n",
    " \n",
    "print('min_sizes: ', min_sizes)\n",
    "print('max_sizes: ', max_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default anchor boxes 數量：\n",
    "\n",
    "38 × 38 × 4 + 19 × 19 × 6 + 10 × 10 × 6 + 5 × 5 × 6 + 3 × 3 × 4 + 1 × 1 × 4 = 8732"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorBox(object):\n",
    "    \"\"\"Compute priorbox coordinates in center-offset form for each source\n",
    "    feature map.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super(PriorBox, self).__init__()\n",
    "        self.image_size = cfg['min_dim']\n",
    "        \n",
    "        # number of priors for feature map location (either 4 or 6)\n",
    "        self.num_priors = len(cfg['aspect_ratios'])\n",
    "        self.variance = cfg['variance'] or [0.1]\n",
    "        self.feature_maps = cfg['feature_maps']\n",
    "        self.min_sizes = cfg['min_sizes']\n",
    "        self.max_sizes = cfg['max_sizes']\n",
    "        self.steps = cfg['steps']\n",
    "        self.aspect_ratios = cfg['aspect_ratios']\n",
    "        self.clip = cfg['clip']\n",
    "        self.version = cfg['name']\n",
    "        \n",
    "        for v in self.variance:\n",
    "            if v <= 0:\n",
    "                raise ValueError('Variances must be greater than 0')\n",
    "\n",
    "    def forward(self):\n",
    "        mean = []\n",
    "        \n",
    "        # 依照 Feature map 大小找出所有的 pixel 中心\n",
    "        # 下方的兩個 loop 會找出 W 個 x 軸 pixel 對上 W 個 y 軸 pixel，假如現在是在 38 x 38 的 feature map 上，就會有 38 x 38 個值\n",
    "        # ex. [0,1],[0,2]..[0,37] [1,1],[1,2]..[1,37]..........[37,37]\n",
    "        for k, f in enumerate(self.feature_maps):\n",
    "            for i, j in product(range(f), repeat=2):\n",
    "                f_k = self.image_size / self.steps[k] ## 如self.steps==8，就是先將原圖size normalize(/300)後再乘上8\n",
    "                # unit center x,y\n",
    "                cx = (j + 0.5) / f_k\n",
    "                cy = (i + 0.5) / f_k\n",
    "\n",
    "                # aspect_ratio: 1\n",
    "                # rel size: min_size\n",
    "                # normalization\n",
    "                # 小的正方形 box\n",
    "                \n",
    "                s_k = self.min_sizes[k] / self.image_size\n",
    "                mean += [cx, cy, s_k, s_k]\n",
    "\n",
    "                # aspect_ratio: 1\n",
    "                # rel size: sqrt(s_k * s_(k+1))\n",
    "                # 大的正方形box\n",
    "                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))\n",
    "                mean += [cx, cy, s_k_prime, s_k_prime]\n",
    "\n",
    "                # rest of aspect ratios\n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    '''aspect ratio 2,3'''\n",
    "                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]\n",
    "                    '''aspect ratio 1/2,1/3'''\n",
    "                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]\n",
    "        \n",
    "        # back to torch land\n",
    "        output = torch.Tensor(mean).view(-1, 4)\n",
    "        if self.clip:\n",
    "            output.clamp_(max=1, min=0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorBox_demo = PriorBox(cfg)\n",
    "\n",
    "print(priorBox_demo.forward().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss 如何設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBoxLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, overlap_thresh, prior_for_matching,\n",
    "                 bkg_label, neg_mining, neg_pos, neg_overlap, encode_target,\n",
    "                 use_gpu=True):\n",
    "        super(MultiBoxLoss, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "        # 預測類別\n",
    "        self.num_classes = num_classes\n",
    "        # 判定為正樣本的 threshold，一般設為0.5\n",
    "        self.threshold = overlap_thresh\n",
    "        # background 自己會有一類，不用 Label，假如我們有 20 類一樣標註 0-19，下方會自己空出一類給 background\n",
    "        self.background_label = bkg_label\n",
    "        self.encode_target = encode_target\n",
    "        self.use_prior_for_matching = prior_for_matching\n",
    "        # OHEM，找出分得最不好的樣品，也就是 confidence score 比較低的正負樣品\n",
    "        self.do_neg_mining = neg_mining\n",
    "        # 負樣品與正樣品的比例，通常是3:1\n",
    "        self.negpos_ratio = neg_pos\n",
    "        self.neg_overlap = neg_overlap\n",
    "        self.variance = cfg['variance']\n",
    "     \n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # 預測會輸出三個值\n",
    "        # 1. loc shape: bounding box 資訊\n",
    "        #       torch.size(batch_size, num_priors, 4)\n",
    "        # 2. conf shape: 每一個 bounding box 的信心程度\n",
    "        #       torch.size(batch_size, num_priors, num_classes)\n",
    "        # 3. priors shape: 預設的 Default box\n",
    "        #       torch.size(num_priors, 4)\n",
    "        loc_data, conf_data, priors = predictions\n",
    "        num = loc_data.size(0)\n",
    "        priors = priors[:loc_data.size(1), :]\n",
    "        num_priors = (priors.size(0))\n",
    "        num_classes = self.num_classes\n",
    "\n",
    "        # match priors (default boxes) and ground truth boxes\n",
    "        loc_t = torch.Tensor(num, num_priors, 4)\n",
    "        conf_t = torch.LongTensor(num, num_priors)\n",
    "        for idx in range(num):\n",
    "            truths = targets[idx][:, :-1].data\n",
    "            labels = targets[idx][:, -1].data\n",
    "            defaults = priors.data\n",
    "            # jaccard 計算每一個 bounding box 與 ground truth 的 IOU\n",
    "            match(self.threshold, truths, defaults, self.variance, labels,\n",
    "                  loc_t, conf_t, idx)\n",
    "        if self.use_gpu:\n",
    "            loc_t = loc_t.cuda()\n",
    "            conf_t = conf_t.cuda()\n",
    "        \n",
    "        # 用 Variable 包裝\n",
    "        loc_t = Variable(loc_t, requires_grad=False)\n",
    "        conf_t = Variable(conf_t, requires_grad=False)\n",
    "\n",
    "        pos = conf_t > 0\n",
    "        num_pos = pos.sum(dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "        pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)\n",
    "        loc_p = loc_data[pos_idx].view(-1, 4)\n",
    "        loc_t = loc_t[pos_idx].view(-1, 4)\n",
    "        # smooth L1 loss（計算 bounding box regression）\n",
    "        loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False)\n",
    "\n",
    "        # Compute max conf across batch for hard negative mining\n",
    "        batch_conf = conf_data.view(-1, self.num_classes)\n",
    "        loss_c = log_sum_exp(batch_conf) - batch_conf.gather(1, conf_t.view(-1, 1))\n",
    "\n",
    "        # Hard Negative Mining\n",
    "        loss_c = loss_c.view(num, -1)\n",
    "        loss_c[pos] = 0\n",
    "        # 排列 confidence 的分數\n",
    "        _, loss_idx = loss_c.sort(1, descending=True)\n",
    "        _, idx_rank = loss_idx.sort(1)\n",
    "        num_pos = pos.long().sum(1, keepdim=True)\n",
    "        # 負樣品取出數量 == negpos_ratio * num_pos\n",
    "        num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(1)-1)\n",
    "        neg = idx_rank < num_neg.expand_as(idx_rank)\n",
    "\n",
    "        # Confidence Loss Including Positive and Negative Examples\n",
    "        pos_idx = pos.unsqueeze(2).expand_as(conf_data)\n",
    "        neg_idx = neg.unsqueeze(2).expand_as(conf_data)\n",
    "        conf_p = conf_data[(pos_idx+neg_idx).gt(0)].view(-1, self.num_classes)\n",
    "        targets_weighted = conf_t[(pos+neg).gt(0)]\n",
    "        # 用 cross entropy 做分類\n",
    "        loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False)\n",
    "\n",
    "        # Sum of losses: L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N\n",
    "        # double 轉成 torch.float64\n",
    "        N = num_pos.data.sum().double()\n",
    "        loss_l = loss_l.double()\n",
    "        loss_c = loss_c.double()\n",
    "        loss_l /= N\n",
    "        loss_c /= N\n",
    "        return loss_l, loss_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 產生我們Loss function，注意這裡的class要包含背景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "criterion = MultiBoxLoss(21, 0.5, True, 0, False, 3, 0.5,False, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 基本設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = build_ssd('train', size=300, num_classes=21)\n",
    "use_pretrained = True\n",
    "\n",
    "if use_pretrained:\n",
    "    net.load_weights('./demo/ssd300_mAP_77.43_v2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要不要使用gpu\n",
    "use_cuda = False\n",
    "\n",
    "# tensor type 會因 cpu 或 gpu 而有所不同\n",
    "if torch.cuda.is_available():\n",
    "    if args.cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    \n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: It looks like you have a CUDA device, but aren't \" +\n",
    "              \"using CUDA.\\nRun with --cuda for optimal training speed.\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "# 使用 gpu 時可以開啟 DataParallel，但當Input是不定大小時，需要關掉\n",
    "if Use_cuda:\n",
    "    net = torch.nn.DataParallel(ssd_net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "#　使用 gpu 時，模型要轉成 cuda 的模式\n",
    "if Use_cuda:\n",
    "    net = net.cuda()\n",
    "    \n",
    "batch_size = 1\n",
    "learning_rate = 0.00001 / batch_size\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入影像格式，假設 batch size 為 4\n",
    "image_in = torch.tensor(torch.rand(4, 3, 300, 300), dtype=torch.float32)\n",
    "\n",
    "# Label 格式，沒有固定長度，看圖像中有幾個 label 就有幾個\n",
    "label_0 = [\n",
    "       [ 0.1804,  0.6076,  0.7701,  0.8485, 0.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 3.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 19.0000],\n",
    "       [ 0.2950,  0.0000,  0.8238,  0.3641, 6.0000]\n",
    "]\n",
    "\n",
    "label_1 = [\n",
    "       [ 0.1804,  0.6076,  0.7701,  0.8485, 13.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 11.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 7.0000],\n",
    "       [ 0.2950,  0.0000,  0.8238,  0.3641, 5.0000]\n",
    "]\n",
    "\n",
    "label_2 = [\n",
    "       [ 0.1804,  0.6076,  0.7701,  0.8485, 0.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 3.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 14.0000],\n",
    "       [ 0.2950,  0.0000,  0.8238,  0.3641, 6.0000]\n",
    "]\n",
    "\n",
    "label_3 = [[ 0.1804,  0.6076,  0.7701,  0.8485, 0.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 3.0000],\n",
    "       [ 0.2250,  0.0000,  0.9238,  0.5641, 19.0000],\n",
    "       [ 0.2950,  0.0000,  0.8238,  0.3641, 6.0000]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "iteration = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    n = 0\n",
    "    loss_sum = []\n",
    "    loc_loss = []\n",
    "    conf_loss = []\n",
    "\n",
    "    for number__ in range(iteration) :\n",
    "        # 需要先使用 Variable 來包裝 tensor 才能輸入到模型\n",
    "        if use_cuda:\n",
    "            image = Variable(image_in.cuda())\n",
    "            y = [\n",
    "                Variable(torch.tensor(label_0).cuda(), volatile=True),\n",
    "                Variable(torch.tensor(label_1).cuda(), volatile=True),\n",
    "                Variable(torch.tensor(label_2).cuda(), volatile=True),\n",
    "                Variable(torch.tensor(label_3).cuda(), volatile=True)\n",
    "            ]\n",
    "        else:\n",
    "            image = Variable(image_in)\n",
    "            y = [\n",
    "                Variable(torch.tensor(label_0), volatile=True),\n",
    "                Variable(torch.tensor(label_1), volatile=True),\n",
    "                Variable(torch.tensor(label_2), volatile=True),\n",
    "                Variable(torch.tensor(label_3), volatile=True)\n",
    "            ]\n",
    "\n",
    "        # Forward Pass\n",
    "        out = net(image)\n",
    "\n",
    "        # Regression Loss and Classification Loss\n",
    "        loss_l, loss_c = criterion(out, y)\n",
    "        loss = loss_l + loss_c\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "\n",
    "        loc_loss.append(loss_l.data.cpu().numpy())\n",
    "        conf_loss.append(loss_c.data.cpu().numpy())\n",
    "        loss_sum.append(loss.data.cpu().numpy())\n",
    "        \n",
    "        # 更新參數\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 清空 Gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        n += 1\n",
    "        if n % 10 == 0:\n",
    "            print('Bounding Box Regression Loss: ', np.mean(loc_loss))\n",
    "            print('Classification Loss: ', np.mean(conf_loss))\n",
    "    \n",
    "    # store weights\n",
    "    torch.save(ssd_net.state_dict(),'weights/weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}